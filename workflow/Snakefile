import glob
import os
from pathlib import Path
from snakemake.io import directory
from snakemake.shell import shell


# CONFIG / GLOBAL CONSTANTS

configfile: "config/config.yaml"



DONORS = list(config["pbmc"].keys())
FASTQC_THREADS = int(config.get("resources", {}).get("fastqc_threads", 2))
STAR_THREADS = int(config.get("resources", {}).get("star_threads", 8))
CUTADAPT_THREADS = int(config.get("resources", {}).get("cutadapt_threads", 4))
TRIM_R2_ADAPTER = str(config.get("trim", {}).get("adapter_r2", "AGATCGGAAGAG"))
TRIM_R2_QUAL = int(config.get("trim", {}).get("q_r2", 20))
TRIM_R2_MINLEN = int(config.get("trim", {}).get("minlen_r2", 20))

# Canonical â†’ legacy path mapping (DO NOT change legacy folder names)
# STARsolo uses "raw" internally; preserve on-disk layout for compatibility

LEGACY_BRANCH = {
    "untrimmed": "raw",
    "trimmed": "trimmed"
}


# Helpers

def touch_done_atomic(done_path: str):
    """
    Create the sentinel file atomically:
    write to a temp file in the same directory, then os.replace().
    """
    done_path = str(done_path)
    d = os.path.dirname(done_path) or "."
    Path(d).mkdir(parents=True, exist_ok=True)

    tmp = done_path + ".tmp"
    with open(tmp, "w") as f:
        f.write("ok\n")
    os.replace(tmp, done_path)


# Config overrides (CLI > config.yaml)

def as_bool(x, default=False):
    if x is None:
        return default
    if isinstance(x, bool):
        return x
    if isinstance(x, (int, float)):
        return bool(x)
    if isinstance(x, str):
        return x.strip().lower() in ("1", "true", "t", "yes", "y", "on")
    return bool(x)

DOWNLOAD_FASTQS = as_bool(config.get("download_fastqs", None),
                         default=as_bool(config.get("io", {}).get("download_fastqs", False)))

BUILD_STAR_INDEX = as_bool(config.get("build_star_index", None),
                           default=as_bool(config.get("ref", {}).get("build_star_index", True)))


# Trim mode helpers (raw vs trimmed execution branches. Cutadapt)
def mode():
    return "trimmed" if trim_enabled() else "raw"


def starsolo_root():
    return f"results/alignment/starsolo/{mode()}"

def trim_enabled():
     # CLI override takes precedence
    if "trim_enabled" in config:
        v = config["trim_enabled"]
        if isinstance(v, str):
            return v.strip().lower() in ("1", "true", "t", "yes", "y", "on")
        return bool(v)
    return bool(config.get("trim", {}).get("enabled", False))


def is_trimmed():
    return trim_enabled()


def starsolo_done(donor, mode):
    return f"results/alignment/starsolo/{mode}/{donor}/starsolo.done"


def resolve_fastq_dir(donor):
    base = config["pbmc"][donor].get("fastq_base", config["pbmc"][donor].get("fastq_dir"))
    if base is None:
        raise ValueError(f"{donor}: need pbmc.{donor}.fastq_base (or fastq_dir)")

    # search base recursively for fastqs
    r1 = sorted(glob.glob(os.path.join(base, "**", "*_R1_*.fastq.gz"), recursive=True))
    r2 = sorted(glob.glob(os.path.join(base, "**", "*_R2_*.fastq.gz"), recursive=True))

    if not r1 or not r2:
        raise ValueError(f"{donor}: no R1/R2 fastqs found under {base}")

    # choose the directory that contains the most R1 files (usually the right one)
    from collections import Counter
    r1_dirs = Counter(os.path.dirname(x) for x in r1)
    fqdir = r1_dirs.most_common(1)[0][0]
    return fqdir


# ALL RULE

rule all:
    input:
        # Always ensure reference is present
        "data/ref/star_index.done",
        "data/ref/whitelist.done",

        # Always ensure raw FASTQs are present (source for everything)
        expand("data/raw/{donor}/fastqs.done", donor=DONORS),

        # Always run RAW QC
        expand("results/qc/fastqc/raw/{donor}/fastqc.done", donor=DONORS),
        "results/qc/multiqc/raw/multiqc_report.html",

        # If trimmed mode: also run trimming + TRIMMED QC
        expand("data/trimmed/{donor}/trim.done", donor=DONORS) if is_trimmed() else [],
        expand("results/qc/fastqc/trimmed/{donor}/fastqc.done", donor=DONORS) if is_trimmed() else [],
        "results/qc/multiqc/trimmed/multiqc_report.html" if is_trimmed() else [],

        # Alignment:
        # - raw mode -> align raw
        # - trimmed mode -> align trimmed ONLY
        expand(
            "results/alignment/starsolo/{m}/{donor}/starsolo.done",
            donor=DONORS,
            m=["trimmed"] if is_trimmed() else ["raw"],
        ),

                # Seurat/QC downstream (only for the active mode)
        expand(
            "results/downstream/seurat/{trim_state}/{donor}/seurat_and_qc/seurat_qc.done",
            donor=DONORS,
            trim_state=["trimmed"] if is_trimmed() else ["untrimmed"],
        ),


                # Seurat/filtering and normalization
        expand(
            "results/downstream/seurat/{trim_state}/{donor}/seurat_filt_normalized/seurat_filt_normalize.done",
            donor=DONORS,
            trim_state=["trimmed"] if is_trimmed() else ["untrimmed"],
        ),

                # Seurat clustering + annotation
        expand(
            "results/downstream/seurat/{trim_state}/{donor}/seurat_cluster_annot/seurat_cluster_annot.done",
            donor=DONORS,
            trim_state=["trimmed"] if is_trimmed() else ["untrimmed"],
        ),

        # Deg and TOST
        expand(
            "results/downstream/deg_and_tost/{trim_state}/deg_and_tost/deg_and_tost.done",
            trim_state=["trimmed"] if is_trimmed() else ["untrimmed"],
        ),






#
# --- UPSTREAM RULES ---
#

# ---- FASTQ acquisition: optional download vs presence check ----

# TODO: Deal with the output folder ambiguity

if DOWNLOAD_FASTQS:
    rule download_fastqs:
        output:
            tar="data/raw/{donor}/fastqs.tar",
            done="data/raw/{donor}/fastqs.done"
        params:
            url=lambda wc: config["pbmc"][wc.donor]["url"]
        log:
            "results/logs/download/{donor}.log"
        shell:
            r"""
            set -euo pipefail
            mkdir -p data/raw/{wildcards.donor}
            mkdir -p results/logs/download

            echo "[START] $(date)" > {log}
            echo "URL: {params.url}" >> {log}

            wget --continue \
                 --tries=50 \
                 --waitretry=10 \
                 --read-timeout=30 \
                 --timeout=30 \
                 -O {output.tar} "{params.url}" >> {log} 2>&1

            tar -xf {output.tar} -C data/raw/{wildcards.donor} >> {log} 2>&1

            tmp="{output.done}.tmp"
            echo ok > "$tmp"
            mv -f "$tmp" "{output.done}"

            echo "[END] $(date)" >> {log}
            """
else:
    rule fastqs_present:
        output:
            done="data/raw/{donor}/fastqs.done"
        params:
            fqdir=lambda wc: resolve_fastq_dir(wc.donor)
        shell:
            r"""
            set -euo pipefail
            test -d "{params.fqdir}"
            ls "{params.fqdir}"/*_R1_*.fastq.gz >/dev/null
            ls "{params.fqdir}"/*_R2_*.fastq.gz >/dev/null
            mkdir -p "$(dirname "{output.done}")"
            tmp="{output.done}.tmp"
            echo ok > "$tmp"
            mv -f "$tmp" "{output.done}"
            """


# ---- QC ----

rule fastqc_raw:
    input:
        "data/raw/{donor}/fastqs.done"
    output:
        done="results/qc/fastqc/raw/{donor}/fastqc.done"
    log:
        "results/logs/qc/fastqc_raw_{donor}.log"
    threads: FASTQC_THREADS
    params:
        fqdir=lambda wc: resolve_fastq_dir(wc.donor)
    shell:
        r"""
        set -euo pipefail
        mkdir -p results/qc/fastqc/raw/{wildcards.donor}
        mkdir -p results/logs/qc

        echo "[START] $(date)" > {log}

        find "{params.fqdir}" -type f \( -name "*.fastq.gz" -o -name "*.fq.gz" \) -print0 \
          | xargs -0 -r -n 1 -P {threads} fastqc \
              -o results/qc/fastqc/raw/{wildcards.donor} >> {log} 2>&1

        tmp="{output.done}.tmp"
        echo ok > "$tmp"
        mv -f "$tmp" "{output.done}"

        echo "[END] $(date)" >> {log}
        """


rule fastqc_trimmed:
    input:
        "data/trimmed/{donor}/trim.done"
    output:
        done="results/qc/fastqc/trimmed/{donor}/fastqc.done"
    threads: FASTQC_THREADS
    params:
        fqdir=lambda wc: f"{config.get('trim', {}).get('out_dir', 'data/trimmed')}/{wc.donor}"
    log:
        "results/logs/qc/fastqc_trimmed_{donor}.log"
    shell:
        r"""
        set -euo pipefail
        mkdir -p results/qc/fastqc/trimmed/{wildcards.donor} results/logs/qc
        echo "[START] $(date)" > {log}
        find "{params.fqdir}" -type f -name "*.fastq.gz" -print0 \
          | xargs -0 -r -n 1 -P {threads} fastqc -o results/qc/fastqc/trimmed/{wildcards.donor} >> {log} 2>&1

        tmp="{output.done}.tmp"
        echo ok > "$tmp"
        mv -f "$tmp" "{output.done}"

        echo "[END] $(date)" >> {log}
        """




rule multiqc_raw:
    input:
        expand("results/qc/fastqc/raw/{donor}/fastqc.done", donor=DONORS)
    output:
        "results/qc/multiqc/raw/multiqc_report.html"
    log:
        "results/logs/qc/multiqc_raw.log"
    shell:
        r"""
        set -euo pipefail
        mkdir -p results/qc/multiqc/raw results/logs/qc

        echo "[START] $(date)" > {log}
        multiqc results/qc/fastqc/raw \
            -o results/qc/multiqc/raw \
            --filename multiqc_report.html \
            >> {log} 2>&1
        echo "[END] $(date)" >> {log}
        """

        
rule multiqc_trimmed:
    input:
        expand("results/qc/fastqc/trimmed/{donor}/fastqc.done", donor=DONORS)
    output:
        "results/qc/multiqc/trimmed/multiqc_report.html"
    log:
        "results/logs/qc/multiqc_trimmed.log"
    shell:
        r"""
        set -euo pipefail
        mkdir -p results/qc/multiqc/trimmed results/logs/qc

        echo "[START] $(date)" > {log}
        multiqc results/qc/fastqc/trimmed \
            -o results/qc/multiqc/trimmed \
            --filename multiqc_report.html \
            >> {log} 2>&1
        echo "[END] $(date)" >> {log}
        """


rule trim_fastqs:
    input:
        raw_done="data/raw/{donor}/fastqs.done",
    output:
        done="data/trimmed/{donor}/trim.done"
    threads: CUTADAPT_THREADS
    log:
        "results/logs/trim/cutadapt_{donor}.log"
    params:
        fqdir=lambda wc: resolve_fastq_dir(wc.donor),
        outdir=lambda wc: f"data/trimmed/{wc.donor}",
        adapter_r2=TRIM_R2_ADAPTER,
        q_r2=TRIM_R2_QUAL,
        minlen_r2=TRIM_R2_MINLEN,

    run:
        import os
        from pathlib import Path

        log_path = str(log[0]) if isinstance(log, (list, tuple)) else str(log)

        r1_files = sorted(glob.glob(f"{params.fqdir}/*_R1_*.fastq.gz"))
        r2_files = sorted(glob.glob(f"{params.fqdir}/*_R2_*.fastq.gz"))

        if not r1_files:
            raise ValueError(f"{wildcards.donor}: no R1 files found in {params.fqdir}")
        if not r2_files:
            raise ValueError(f"{wildcards.donor}: no R2 files found in {params.fqdir}")
        if len(r1_files) != len(r2_files):
            raise ValueError(
                f"{wildcards.donor}: mismatch R1({len(r1_files)}) vs R2({len(r2_files)}) in {params.fqdir}"
            )

        Path(params.outdir).mkdir(parents=True, exist_ok=True)
        Path(os.path.dirname(log_path)).mkdir(parents=True, exist_ok=True)

        with open(log_path, "w") as lf:
            lf.write(f"[START] donor={wildcards.donor}\n")
            lf.write(f"fqdir={params.fqdir}\n")

        # Track temp outputs so we can clean them if anything fails
        tmp_outputs = []

        try:
            for r1_in, r2_in in zip(r1_files, r2_files):
                r1_base = os.path.basename(r1_in)
                r2_base = os.path.basename(r2_in)

                r1_out = str(Path(params.outdir) / r1_base)
                r2_out = str(Path(params.outdir) / r2_base)

                # Write to temp files first
                r1_tmp = r1_out + ".tmp.gz"
                r2_tmp = r2_out + ".tmp.gz"
                tmp_outputs.extend([r1_tmp, r2_tmp])

                # Ensure no stale tmp from a previous crash
                for p in (r1_tmp, r2_tmp):
                    try:
                        os.remove(p)
                    except FileNotFoundError:
                        pass

                cmd = [
                    "cutadapt",
                    "-A", params.adapter_r2,
                    "-q", "0",
                    "-Q", f"0,{params.q_r2}",
                    "--minimum-length", f"0:{params.minlen_r2}",
                    "--pair-filter=any",
                    "-j", str(threads),
                    "-o", r1_tmp,
                    "-p", r2_tmp,
                    r1_in, r2_in,
                ]



                shell(" ".join(cmd) + f" >> {log_path} 2>&1")

                # Atomic-ish publish: only now move temp -> final
                os.replace(r1_tmp, r1_out)
                os.replace(r2_tmp, r2_out)

            # Only create sentinel after all lanes succeeded and were published
            touch_done_atomic(output.done)

        except Exception:
            # Best-effort cleanup of temp files if something failed mid-run
            for p in tmp_outputs:
                try:
                    os.remove(p)
                except FileNotFoundError:
                    pass
            raise



# ---- Reference / index ----

rule download_genome_fasta:
    output:
        fasta=config["ref"]["genome_fasta"]
    params:
        url=config["ref"]["genome_fasta_url"]
    log:
        "results/logs/ref/genome_fasta.log"
    shell:
        r"""
        set -euo pipefail
        mkdir -p "$(dirname "{output.fasta}")"
        mkdir -p results/logs/ref

        curl -L --fail --retry 10 --retry-delay 5 \
          "{params.url}" \
          | gunzip -c > "{output.fasta}" 2>> "{log}"

        test -s "{output.fasta}"
        """

rule download_gtf:
    output:
        gtf=config["ref"]["gtf"]
    params:
        url=config["ref"]["gtf_url"]
    log:
        "results/logs/ref/gtf.log"
    shell:
        r"""
        set -euo pipefail
        mkdir -p "$(dirname "{output.gtf}")"
        mkdir -p results/logs/ref

        curl -L --fail --retry 10 --retry-delay 5 \
          "{params.url}" \
          | gunzip -c > "{output.gtf}" 2>> "{log}"

        test -s "{output.gtf}"
        """



if BUILD_STAR_INDEX:
    rule star_index:
        input:
            fasta=config["ref"]["genome_fasta"],
            gtf=config["ref"]["gtf"]
        output:
            idx=directory(config["ref"]["star_index"]),
            done="data/ref/star_index.done"
        threads: STAR_THREADS
        params:
            sjdbOverhang=89
        log:
            "results/logs/ref/star_index.log"
        shell:
            r"""
            set -euo pipefail
            mkdir -p {output.idx}
            mkdir -p results/logs/ref

            STAR \
              --runThreadN {threads} \
              --runMode genomeGenerate \
              --genomeDir {output.idx} \
              --genomeFastaFiles {input.fasta} \
              --sjdbGTFfile {input.gtf} \
              --sjdbOverhang {params.sjdbOverhang} \
              > {log} 2>&1

            tmp="{output.done}.tmp"
            echo ok > "$tmp"
            mv -f "$tmp" "{output.done}"
            """
else:
    rule star_index_present:
        output:
            idx=directory(config["ref"]["star_index"]),
            done="data/ref/star_index.done"
        log:
            "results/logs/ref/star_index_present.log"
        shell:
            r"""
            set -euo pipefail
            mkdir -p results/logs/ref
            echo "[START] $(date)" > {log}

            # Basic validation: directory exists and is not empty
            test -d "{output.idx}"
            ls -A "{output.idx}" >/dev/null

            tmp="{output.done}.tmp"
            echo ok > "$tmp"
            mv -f "$tmp" "{output.done}"

            echo "[END] $(date)" >> {log}
            """

rule whitelist_present:
    input:
        wl=config["ref"]["whitelist"]
    output:
        done="data/ref/whitelist.done"
    shell:
        r"""
        set -euo pipefail
        mkdir -p "$(dirname "{output.done}")"

        test -s "{input.wl}"

        tmp="{output.done}.tmp"
        echo ok > "$tmp"
        mv -f "$tmp" "{output.done}"
        """
        

# ---- Alignment / counting ----

def starsolo_mode():
    return "trimmed" if is_trimmed() else "raw"

rule starsolo_raw:
    threads: STAR_THREADS
    log:
        "results/logs/alignment/starsolo_raw_{donor}.log"
    input:
        idx=config["ref"]["star_index"],
        index_done="data/ref/star_index.done",
        wl=config["ref"]["whitelist"],
        wl_done="data/ref/whitelist.done",
        fastqs_done="data/raw/{donor}/fastqs.done",
    output:
        done="results/alignment/starsolo/raw/{donor}/starsolo.done"
    params:
        outdir="results/alignment/starsolo/raw/{donor}",
        fqdir=lambda wc: resolve_fastq_dir(wc.donor),
    shell:
        r"""
        set -euo pipefail
        mkdir -p {params.outdir}
        mkdir -p results/logs/alignment

        R1="$(ls {params.fqdir}/*_R1_*.fastq.gz | paste -sd, -)"
        R2="$(ls {params.fqdir}/*_R2_*.fastq.gz | paste -sd, -)"
        test -n "$R1"
        test -n "$R2"

        STAR \
          --runThreadN {threads} \
          --genomeDir {input.idx} \
          --readFilesIn "$R2" "$R1" \
          --readFilesCommand zcat \
          --outFileNamePrefix {params.outdir}/ \
          --soloType CB_UMI_Simple \
          --soloCBwhitelist {input.wl} \
          --soloBarcodeMate 2 \
          --soloUMIlen 12 \
          --soloCBlen 16 \
          --soloBarcodeReadLength 28 \
          --soloFeatures Gene \
          --outSAMtype None \
          > {log} 2>&1

        tmp="{output.done}.tmp"
        echo ok > "$tmp"
        mv -f "$tmp" "{output.done}"
        """



rule starsolo_trimmed:
    threads: STAR_THREADS
    log:
        "results/logs/alignment/starsolo_trimmed_{donor}.log"
    input:
        idx=config["ref"]["star_index"],
        index_done="data/ref/star_index.done",
        wl=config["ref"]["whitelist"],
        wl_done="data/ref/whitelist.done",
        trim_done="data/trimmed/{donor}/trim.done",
    output:
        done="results/alignment/starsolo/trimmed/{donor}/starsolo.done"
    params:
        outdir="results/alignment/starsolo/trimmed/{donor}",
        fqdir="data/trimmed/{donor}",
    shell:
        r"""
        set -euo pipefail
        mkdir -p {params.outdir}
        mkdir -p results/logs/alignment

        # Build comma-separated lane lists at runtime (AFTER trimming has run)
        R1="$(ls {params.fqdir}/*_R1_*.fastq.gz | paste -sd, -)"
        R2="$(ls {params.fqdir}/*_R2_*.fastq.gz | paste -sd, -)"

        # Hard fail with a clear message if still missing
        test -n "$R1"
        test -n "$R2"

        STAR \
          --runThreadN {threads} \
          --genomeDir {input.idx} \
          --readFilesIn "$R2" "$R1" \
          --readFilesCommand zcat \
          --outFileNamePrefix {params.outdir}/ \
          --soloType CB_UMI_Simple \
          --soloCBwhitelist {input.wl} \
          --soloBarcodeMate 2 \
          --soloUMIlen 12 \
          --soloCBlen 16 \
          --soloBarcodeReadLength 28 \
          --soloFeatures Gene \
          --outSAMtype None \
          > {log} 2>&1

        tmp="{output.done}.tmp"
        echo ok > "$tmp"
        mv -f "$tmp" "{output.done}"
        """

# 
# --- DOWNSTREAM RULES
#

rule seurat_qc:
    input:
        starsolo_done=lambda wc: f"results/alignment/starsolo/{LEGACY_BRANCH[wc.trim_state]}/{wc.donor}/starsolo.done"
    output:
        done="results/downstream/seurat/{trim_state}/{donor}/seurat_and_qc/seurat_qc.done"
        # (optional) only keep this if your R script truly writes it:
        # rds="results/downstream/seurat/{trim_state}/{donor}/seurat_object.rds"
    params:
        filtered_dir=lambda wc: f"results/alignment/starsolo/{LEGACY_BRANCH[wc.trim_state]}/{wc.donor}",
        outdir=lambda wc: f"results/downstream/seurat/{wc.trim_state}/{wc.donor}/seurat_and_qc"
    shell:
        r"""
        set -euo pipefail
        mkdir -p "{params.outdir}"

        MTX="{params.filtered_dir}/Solo.out/Gene/filtered/matrix.mtx"
        BARCODES="{params.filtered_dir}/Solo.out/Gene/filtered/barcodes.tsv"
        FEATURES="{params.filtered_dir}/Solo.out/Gene/filtered/features.tsv"


        test -s "$MTX"
        test -s "$BARCODES"
        test -s "$FEATURES"

        Rscript scripts/build_seurat_objects_qc.R \
            --mtx "$MTX" \
            --features "$FEATURES" \
            --barcodes "$BARCODES" \
            --outdir "{params.outdir}" \
            --donor "{wildcards.donor}"

        tmp="{output.done}.tmp"
        echo ok > "$tmp"
        mv -f "$tmp" "{output.done}"
        """

rule seurat_filt_normalize:
    input:
        seurat_done="results/downstream/seurat/{trim_state}/{donor}/seurat_and_qc/seurat_qc.done"
    output:
        done="results/downstream/seurat/{trim_state}/{donor}/seurat_filt_normalized/seurat_filt_normalize.done"
    params:
        seurat_dir=lambda wc: f"results/downstream/seurat/{wc.trim_state}/{wc.donor}/seurat_and_qc",
        outdir=lambda wc: f"results/downstream/seurat/{wc.trim_state}/{wc.donor}/seurat_filt_normalized",
        norm_method=lambda wc: str(config.get("seurat_normalization", {}).get("method", "LogNormalize")),
        scale_factor=lambda wc: int(config.get("seurat_normalization", {}).get("scale_factor", 10000)),
        hvg_method=lambda wc: str(config.get("seurat_normalization", {}).get("hvg_method", "vst")),
        hvg_nfeatures=lambda wc: int(config.get("seurat_normalization", {}).get("hvg_nfeatures", 2000)),
        vars_to_regress=lambda wc: ",".join(config.get("seurat_normalization", {}).get("vars_to_regress", ["percent.mt"])),
        scale_features=lambda wc: str(config.get("seurat_normalization", {}).get("scale_features", "hvg")),

    shell:
        r"""
        set -euo pipefail
        mkdir -p "{params.outdir}"

        SEURAT="{params.seurat_dir}/{wildcards.donor}_object.rds"
        QC="{params.seurat_dir}/qc_metrics.tsv"
        
        test -s "$SEURAT"
        test -s "$QC"
    

        Rscript scripts/qcfilt_normalize_seurat.R \
            --seurat "$SEURAT" \
            --qc_metrics "$QC" \
            --outdir "{params.outdir}" \
            --donor "{wildcards.donor}" \
            --norm_method "{params.norm_method}" \
            --scale_factor {params.scale_factor} \
            --hvg_method "{params.hvg_method}" \
            --hvg_nfeatures {params.hvg_nfeatures} \
            --vars_to_regress "{params.vars_to_regress}" \
            --scale_features "{params.scale_features}"


        tmp="{output.done}.tmp"
        echo ok > "$tmp"
        mv -f "$tmp" "{output.done}"
        """


rule seurat_cluster_annot:
    input:
        norm_done="results/downstream/seurat/{trim_state}/{donor}/seurat_filt_normalized/seurat_filt_normalize.done"
    output:
        done="results/downstream/seurat/{trim_state}/{donor}/seurat_cluster_annot/seurat_cluster_annot.done",
        rds="results/downstream/seurat/{trim_state}/{donor}/seurat_cluster_annot/{donor}_annotated_object.rds"
    params:
        # normalized object produced by qcfilt_normalize_seurat.R
        seurat_rds=lambda wc: (
            f"results/downstream/seurat/{wc.trim_state}/{wc.donor}/seurat_filt_normalized/"
            f"{wc.donor}_qcfilt_norm_object.rds"
        ),
        markers="scripts/markers_pbmc.R",
        outdir=lambda wc: f"results/downstream/seurat/{wc.trim_state}/{wc.donor}/seurat_cluster_annot",
        # optional knobs (only include if you want config control now)
        dims=lambda wc: int(config.get("seurat_annotation", {}).get("dims", 30)),
        resolution=lambda wc: float(config.get("seurat_annotation", {}).get("resolution", 0.3)),
        seed=lambda wc: int(config.get("seurat_annotation", {}).get("seed", 1)),
    shell:
        r"""
        set -euo pipefail
        mkdir -p "{params.outdir}"

        test -s "{params.seurat_rds}"
        test -s "{params.markers}"

        Rscript scripts/cell_clustering_and_annotation.R \
            --seurat  "{params.seurat_rds}" \
            --markers "{params.markers}" \
            --outdir  "{params.outdir}" \
            --donor   "{wildcards.donor}" \
            --dims        {params.dims} \
            --resolution  {params.resolution} \
            --seed        {params.seed}
        
        # verify the declared output exists BEFORE declaring done
        test -s "{output.rds}"

        tmp="{output.done}.tmp"
        echo ok > "$tmp"
        mv -f "$tmp" "{output.done}"
        """

rule deg_and_tost:
    input:
        annot_done=lambda wc: [
            f"results/downstream/seurat/{wc.trim_state}/{d}/seurat_cluster_annot/seurat_cluster_annot.done"
            for d in DONORS
        ],
        seurat_rds=lambda wc: [
            f"results/downstream/seurat/{wc.trim_state}/{d}/seurat_cluster_annot/{d}_annotated_object.rds"
            for d in DONORS
        ],
        celltype_sets="scripts/celltype_sets.R",
    output:
        done="results/downstream/deg_and_tost/{trim_state}/deg_and_tost/deg_and_tost.done"
    params:
        outdir=lambda wc: f"results/downstream/deg_and_tost/{wc.trim_state}/deg_and_tost",
        assay=lambda wc: str(config.get("deg_and_tost", {}).get("assay", "RNA")),
        min_baseMean=lambda wc: int(config.get("deg_and_tost", {}).get("min_baseMean", 10)),
        min_cells_per_group=lambda wc: int(config.get("deg_and_tost", {}).get("min_cells_per_group", 50)),
        marker_padj=lambda wc: float(config.get("deg_and_tost", {}).get("marker_padj", 1e-10)),
        marker_lfc=lambda wc: float(config.get("deg_and_tost", {}).get("marker_lfc", 3)),
        equiv_alpha=lambda wc: float(config.get("deg_and_tost", {}).get("equiv_alpha", 0.05)),
        equiv_delta=lambda wc: float(config.get("deg_and_tost", {}).get("equiv_delta", 0.75)),
        seed=lambda wc: int(config.get("deg_and_tost", {}).get("seed", 42)),
    shell:
        r"""
        set -euo pipefail
        mkdir -p "{params.outdir}"

        SEURAT_CSV="$(printf "%s," {input.seurat_rds} | sed 's/,$//')"
        test -n "$SEURAT_CSV"
        test -s "{input.celltype_sets}"

        Rscript scripts/pseudobulk_deg_tost_gsea.R \
            --seurat "$SEURAT_CSV" \
            --celltype_sets "{input.celltype_sets}" \
            --outdir "{params.outdir}" \
            --assay {params.assay} \
            --min_baseMean {params.min_baseMean} \
            --min_cells_per_group {params.min_cells_per_group} \
            --marker_padj {params.marker_padj} \
            --marker_lfc {params.marker_lfc} \
            --equiv_alpha {params.equiv_alpha} \
            --equiv_delta {params.equiv_delta} \
            --seed {params.seed}

        tmp="{output.done}.tmp"
        echo ok > "$tmp"
        mv -f "$tmp" "{output.done}"
        """
